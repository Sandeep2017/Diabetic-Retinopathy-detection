{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DR_2015_7GB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFqPuZvK5uoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!ls -lha kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHGDmEGY6JU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6c78dac8-5666-4f68-92fb-1cc83eef401e"
      },
      "source": [
        "!kaggle datasets download -d tanlikesmath/diabetic-retinopathy-resized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading diabetic-retinopathy-resized.zip to /content\n",
            "100% 7.24G/7.25G [02:46<00:00, 36.1MB/s]\n",
            "100% 7.25G/7.25G [02:46<00:00, 46.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFooWRP86JXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/diabetic-retinopathy-resized.zip' -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uf66vTp6JY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31xPMhjI6JdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 'resized_train_cropped' dir contains black border cropped images.\n",
        "# This script will first resize every (.jpg) image under that dir and then apply CLAHE and save it in-place.\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "os.chdir(r'/content/data/resized_train_cropped/resized_train_cropped')\n",
        "i = os.walk(os.getcwd())\n",
        "d = (256,256)\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "for a,b,c in i:\n",
        "  for z in range(len(c)):\n",
        "      path = os.path.join(a,c[z])\n",
        "      #print(path)\n",
        "      image = cv2.imread(path)\n",
        "      image = cv2.resize(image, d, interpolation = cv2.INTER_AREA)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      image = clahe.apply(image)\n",
        "      cv2.imwrite(path, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ug1l1Io8YdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindf=pd.read_csv('/content/datasets_131128_418031_trainLabels_cropped.csv',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zMDRrAIAI-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e60140c0-2f56-4f23-d546-780af86f0aaf"
      },
      "source": [
        "traindf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>image</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>13_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>15_left</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0 Unnamed: 0.1     image level\n",
              "0          0            0   10_left     0\n",
              "1          1            1  10_right     0\n",
              "2          2            2   13_left     0\n",
              "3          3            3  13_right     0\n",
              "4          4            4   15_left     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzVfmyPAJDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXmpzkihB3ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Layer, Input, MaxPooling2D, ReLU, Add, GlobalAveragePooling2D, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvVnPlHAkY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f98075f-374d-4d83-9562-c28f87504b8c"
      },
      "source": [
        "inputs = Input(shape = (256, 256, 3))\n",
        "\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(rate=0.7)(x)\n",
        "x = Dense(units=128, activation='relu')(x)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "x = Dense(units=64, activation='relu')(x)\n",
        "\n",
        "\n",
        "output = Dense(units=5, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 256, 256, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 256, 256, 16)      2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_8 (Separabl (None, 128, 128, 32)      688       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_9 (Separabl (None, 128, 128, 32)      1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_10 (Separab (None, 64, 64, 64)        2400      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_11 (Separab (None, 64, 64, 64)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_12 (Separab (None, 32, 32, 128)       8896      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_13 (Separab (None, 32, 32, 128)       17664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_14 (Separab (None, 16, 16, 256)       34176     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_15 (Separab (None, 16, 16, 256)       68096     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,606,053\n",
            "Trainable params: 8,605,093\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwqXehbNCltT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Appending (.jpeg) ext. to every image name in the dataframe\n",
        "def append_ext(fn):\n",
        "    return fn+\".jpeg\"\n",
        "\n",
        "traindf[\"image\"] = traindf[\"image\"].apply(append_ext)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xClbLbe_AkdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ca27bcde-a350-4b96-a5a4-bdafac22aa3b"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
        "\n",
        "# Flow from dataframe\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "dataframe = traindf,\n",
        "directory = \"/content/data/resized_train_cropped/resized_train_cropped\",\n",
        "x_col = \"image\",\n",
        "y_col = \"level\",\n",
        "subset = \"training\",\n",
        "batch_size = 32,\n",
        "seed = 42,\n",
        "shuffle = True,\n",
        "class_mode = \"categorical\",\n",
        "target_size = (256,256))\n",
        "\n",
        "valid_generator = datagen.flow_from_dataframe(\n",
        "dataframe = traindf,\n",
        "directory = \"/content/data/resized_train_cropped/resized_train_cropped\",\n",
        "x_col = \"image\",\n",
        "y_col = \"level\",\n",
        "subset = \"validation\",\n",
        "batch_size = 32,\n",
        "seed = 42,\n",
        "shuffle = True,\n",
        "class_mode = \"categorical\",\n",
        "target_size = (256,256))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 26331 validated image filenames belonging to 5 classes.\n",
            "Found 8777 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnvf0KXfAkf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg9OyCgpGgHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_weights_path = '/content/weights'\n",
        "if not os.path.exists(save_weights_path):\n",
        "  os.mkdir(save_weights_path)\n",
        "\n",
        "cpk_path = save_weights_path+'/weights_{epoch:03d}-{val_accuracy:.4f}.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnUOfbBFGj2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " checkpoint = ModelCheckpoint(\n",
        "  filepath=cpk_path,\n",
        "  monitor='val_accuracy',\n",
        "  mode='max',\n",
        "  verbose=1,\n",
        "  save_best_only=True,\n",
        "  save_weights_only=True,\n",
        "  save_freq='epoch'\n",
        "  )\n",
        "\n",
        "reducelr = ReduceLROnPlateau(\n",
        "  monitor='val_loss',\n",
        "  factor=0.2,\n",
        "  patience=5,\n",
        "  verbose=1\n",
        "  )\n",
        "\n",
        "callbacks = [checkpoint, reducelr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ucB3hutGEB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "07599026-a58d-48bc-f7ed-07a8617dcfa2"
      },
      "source": [
        "batch_size = 32\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = train_generator.samples // batch_size,\n",
        "                              epochs = 10,\n",
        "                              validation_data = valid_generator,\n",
        "                              validation_steps = valid_generator.samples // batch_size,\n",
        "                              callbacks=[checkpoint, reducelr]\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.7361\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72776, saving model to /content/weights/weights_001-0.7278.h5\n",
            "822/822 [==============================] - 267s 325ms/step - loss: 0.9106 - accuracy: 0.7361 - val_loss: 0.8898 - val_accuracy: 0.7278 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.7371\n",
            "Epoch 00002: val_accuracy improved from 0.72776 to 0.72787, saving model to /content/weights/weights_002-0.7279.h5\n",
            "822/822 [==============================] - 267s 325ms/step - loss: 0.8860 - accuracy: 0.7371 - val_loss: 0.8841 - val_accuracy: 0.7279 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8741 - accuracy: 0.7374\n",
            "Epoch 00003: val_accuracy did not improve from 0.72787\n",
            "822/822 [==============================] - 267s 325ms/step - loss: 0.8741 - accuracy: 0.7374 - val_loss: 0.8763 - val_accuracy: 0.7279 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8709 - accuracy: 0.7373\n",
            "Epoch 00004: val_accuracy improved from 0.72787 to 0.72799, saving model to /content/weights/weights_004-0.7280.h5\n",
            "822/822 [==============================] - 268s 326ms/step - loss: 0.8709 - accuracy: 0.7373 - val_loss: 0.8788 - val_accuracy: 0.7280 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8696 - accuracy: 0.7373\n",
            "Epoch 00005: val_accuracy did not improve from 0.72799\n",
            "822/822 [==============================] - 268s 327ms/step - loss: 0.8696 - accuracy: 0.7373 - val_loss: 0.8775 - val_accuracy: 0.7280 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8686 - accuracy: 0.7373\n",
            "Epoch 00006: val_accuracy improved from 0.72799 to 0.72810, saving model to /content/weights/weights_006-0.7281.h5\n",
            "822/822 [==============================] - 268s 327ms/step - loss: 0.8686 - accuracy: 0.7373 - val_loss: 0.8797 - val_accuracy: 0.7281 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.7373\n",
            "Epoch 00007: val_accuracy did not improve from 0.72810\n",
            "822/822 [==============================] - 270s 328ms/step - loss: 0.8691 - accuracy: 0.7373 - val_loss: 0.8773 - val_accuracy: 0.7278 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8669 - accuracy: 0.7373\n",
            "Epoch 00008: val_accuracy did not improve from 0.72810\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "822/822 [==============================] - 268s 326ms/step - loss: 0.8669 - accuracy: 0.7373 - val_loss: 0.8764 - val_accuracy: 0.7278 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8644 - accuracy: 0.7375\n",
            "Epoch 00009: val_accuracy did not improve from 0.72810\n",
            "822/822 [==============================] - 269s 328ms/step - loss: 0.8644 - accuracy: 0.7375 - val_loss: 0.8771 - val_accuracy: 0.7278 - lr: 2.0000e-04\n",
            "Epoch 10/10\n",
            "822/822 [==============================] - ETA: 0s - loss: 0.8647 - accuracy: 0.7373\n",
            "Epoch 00010: val_accuracy did not improve from 0.72810\n",
            "822/822 [==============================] - 268s 327ms/step - loss: 0.8647 - accuracy: 0.7373 - val_loss: 0.8763 - val_accuracy: 0.7280 - lr: 2.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}